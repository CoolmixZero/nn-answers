# NN answers

- ## 1.A tutoriál
1. Aké vlastnosti má splňať systém UI?

    Система искусственного интеллекта (UI) должна обладать следующими характеристиками:
    - Способность обрабатывать и анализировать большие объемы данных.
    - Умение распознавать и понимать естественный язык.
    - Автоматическое обучение и принятие решений на основе полученных знаний.
    - Возможность работы в реальном времени.
    - Интеграция с другими системами и интерфейсами.
    - Безопасность и защита данных.
2. Aké sú dva základné prístupy pri riešení problémov UI? Popíšte ich. Aká je predpokladaná perspektíva?
    Существуют два основных подхода к решению проблем в UI:
    - Символьный подход: в этом подходе используются правила и символические операции для решения задач. Он основан на заранее заданных правилах и логических выражениях, и позволяет представлять знания в явном виде. Однако этот подход ограничен в том, что он не может самостоятельно извлекать знания из данных.

    - Подход на основе нейронных сетей: в этом подходе используются нейронные сети для решения задач. Нейронные сети имитируют работу человеческого мозга и способны обучаться на основе больших объемов данных. Они могут автоматически извлекать знания из данных и принимать решения. Этот подход имеет большой потенциал и предполагается, что он будет иметь значительные перспективы в будущем.
3. čo je to NN?
    Нейронная сеть (NN) - это математическая модель, которая имитирует работу нейронов в человеческом мозге. Она состоит из соединенных между собой искусственных нейронов, которые обмениваются сигналами и выполняют вычисления. Нейронные сети используются для обработки информации, распознавания образов, прогнозирования и других задач, требующих обработки и анализа данных.
4. Akú významnú vlastnosť majú NN ? čo dokážu ? Aké sú základné aplikačné oblasti ?
    Важной особенностью нейронных сетей является их способность обучаться на основе данных. Они могут автоматически извлекать закономерности и паттерны из больших объемов информации и принимать решения на основе этих знаний. Основные применения нейронных сетей включают распознавание образов, обработку естественного языка, прогнозирование и управление.
5. Aké základné okruhy problémov pri štúdiu NN existujú?

    Основные области проблем при изучении нейронных сетей включают:
    - Проектирование и обучение нейронных сетей.
    - Выбор архитектуры и топологии сетей.
    - Разработка алгоритмов обучения и оптимизации.
    - Работа с большими объемами данных.
    - Преодоление проблемы переобучения и недообучения.
6. Aký je rozdiel medzi NN a ľudským mozgom ? Je ľudský mozog napodobniteľný ?

    Основные различия между нейронными сетями и человеческим мозгом:
    - Нейронные сети являются математическими моделями, в то время как человеческий мозг - биологический орган.
    - Нейронные сети работают на основе численных вычислений, в то время как человеческий мозг обрабатывает информацию в более сложной форме.
    - Нейронные сети ограничены своими алгоритмами и архитектурой, в то время как человеческий мозг обладает широким спектром возможностей, включая эмоции, интуицию и креативность.
    Полная имитация человеческого мозга с использованием нейронных сетей пока что невозможна, но исследования в этой области продолжаются.
7. Ktoré sú základné historické medzníky vo vývoji teórie NN?
    
    Основными историческими вехами в развитии теории нейронных сетей были:
    - Появление персептрона в 1957 году, который был одной из первых моделей нейронной сети.
    - Развитие обратного распространения ошибки в 1980-х годах, что привело к возрождению интереса к нейронным сетям.
    - Разработка сверточных нейронных сетей в 1990-х годах, которые стали эффективными для обработки изображений и распознавания образов.
    - Появление глубоких нейронных сетей и использование графических процессоров для ускорения вычислений в 2000-х годах, что стало основой для успеха глубокого обучения.
8. Charakterizujte základnú procesnú jednotku neurón
    
    Основная обрабатывающая единица нейрона состоит из:
    - Входов, через которые поступает информация.
    - Весов, которые определяют важность каждого входа.
    - Сумматора, который суммирует взвешенные входы.
    - Функции активации, которая определяет активность нейрона в зависимости от сумматора.
9. čo je to učenie? Aký je rozdiel medzi činnosťou NN počas a mimo učenia ?
    Обучение - это процесс, при котором нейронная сеть адаптируется к входным данным и обновляет свои веса для достижения лучшей производительности. Во время обучения нейронная сеть использует обратное распространение ошибки для корректировки весов и улучшения своих прогностических способностей. Во время работы без обучения нейронная сеть просто использует уже установленные веса для выполнения задачи.
10. Aké sú základné paradigmy učenia? Aký je rozdiel medzi kontrolovaným a nekontrolovaným učením?

    Основные парадигмы обучения включают:

    - Контролируемое обучение: в этой парадигме сеть обучается на основе пар вход-выход, где требуемые выходы известны заранее. Сеть пытается минимизировать разницу между предсказанными и требуемыми выходами путем корректировки весов.

    - Неконтролируемое обучение: в этой парадигме сеть обучается на неразмеченных данных без явно заданных выходных значений. Она самостоятельно ищет скрытые структуры и закономерности в данных и формирует внутреннюю представление.
11. Aké sú základné druhy kontrolovaného učenia, nekontrolovaného učenia a učenia na základe stavu systému?
    Основные виды контролируемого обучения, неконтролируемого обучения и обучения на основе состояния системы включают:
    - Контролируемое обучение: классификация и регрессия.
    - Неконтролируемое обучение: кластеризация и снижение размерности.
    - Обучение на основе состояния системы: управление и обратная связь.

- ## 1.B. tutoriál
1. Prečo je nutné hovoriť o stabilite NN a kedy ? Aká je kriterálna funkcia stability?
    Почему важно говорить о стабильности нейронных сетей (NN) и когда это необходимо? Какова критериальная функция стабильности?
    Стабильность нейронных сетей является важным аспектом исследования и применения NN. Стабильность означает, что небольшие изменения входных данных или параметров сети не должны вызывать значительные изменения в ее выходах. Это важно для обеспечения надежности и предсказуемости работы сети.

    Критериальная функция стабильности зависит от конкретной задачи и может быть определена по многим факторам, таким как устойчивость выходных значений, влияние шумовых сигналов, устойчивость к изменениям весов и другие параметры сети. Она обычно определяется с использованием математических моделей и алгоритмов для оценки и контроля стабильности сети.
2. Aký je rozdiel medzi konvergenciou NN a stabilitou NN?
    В чем разница между сходимостью и стабильностью нейронных сетей?
    Сходимость нейронной сети означает, что при обучении сети на задаче ошибка сети уменьшается и приближается к нулю. Это процесс настройки весов и параметров сети для достижения оптимальных результатов.

    Стабильность нейронной сети, как уже упоминалось, означает, что малые изменения входных данных или параметров сети не должны вызывать значительные изменения в ее выходах. Это обеспечивает надежность и предсказуемость работы сети.

    Таким образом, сходимость является процессом обучения, а стабильность - свойством работы сети после завершения обучения.
3. Aké sú typy úloh riešených pomocou NN?

    Нейронные сети могут использоваться для решения различных типов задач, включая:
    - Классификация: определение принадлежности объекта к определенному классу.
    - Регрессия: предсказание непрерывной переменной на основе входных данных.
    - Кластеризация: группировка объектов в подмножества (кластеры) на основе их сходства.
    - Обработка естественного языка: анализ и понимание текста на естественном языке.
    - Распознавание образов: идентификация и классификация изображений или образов.
    - Управление и оптимизация: решение задач оптимального управления и оптимизации параметров.
4. Aká je topológia perceptrónu? Aká je úloha základného perceptrónu a jeho činnosť?
    Какова топология перцептрона? Какова основная задача базового перцептрона и его функционирование?
    Перцептрон - это простая модель нейронной сети, состоящая из одного или нескольких нейронов. Основная топология перцептрона состоит из входного слоя, в котором находятся входные нейроны, и выходного слоя с одним или несколькими выходными нейронами. Каждый нейрон связан с нейронами предыдущего и следующего слоев с помощью весов.

    Основная задача перцептрона заключается в классификации или принятии решений на основе входных данных. Он может принимать входные значения, умножать их на соответствующие веса, суммировать и применять функцию активации для получения выходного значения. Веса перцептрона обучаются с использованием алгоритма обратного распространения ошибки.
5. čo vlastne chceme dokázať konvergenciou perceptrónu ?
    Что мы хотим достичь сходимостью перцептрона?
    Цель сходимости перцептрона заключается в том, чтобы обучить перцептрон находить правильные веса, которые позволят ему правильно классифицировать или принимать решения на основе входных данных. Сходимость перцептрона достигается путем корректировки весов на каждом шаге обучения в соответствии с алгоритмом обратного распространения ошибки.
6. Aký je rozdiel medzi lineárnou a nelineárnou separabilitou ? čo je to to XOR problém?
    В чем разница между линейной и нелинейной сепарабельностью? Что такое проблема XOR?
    Линейная сепарабельность означает, что два класса объектов можно линейно разделить гиперплоскостью в пространстве признаков. Это означает, что существует линейное правило, которое может правильно классифицировать объекты.

    Нелинейная сепарабельность означает, что классы объектов нельзя линейно разделить. Требуется использование нелинейных правил и более сложных моделей для правильной классификации.

    Проблема XOR является примером нелинейной сепарабельности. XOR - это логическая операция, которая возвращает истинное значение только в том случае, если один из входов истинен, а другой - ложный. Признаки XOR невозможно правильно классифицировать с использованием линейной модели или одного перцептрона. Она требует нелинейных правил или более сложной модели, такой как многослойный перцептрон.
7. Môžte komentovať terminologický problém perceptrónu ?
    Можете прокомментировать терминологическую проблему перцептрона?
    Терминологическая проблема перцептрона возникла изначально в связи с его ограничениями. Перцептрон может корректно классифицировать только линейно сепарабельные задачи. Если данные не являются линейно сепарабельными, то перцептрон не может достичь сходимости и правильно решить задачу.

    Однако, с появлением более сложных моделей нейронных сетей, таких как многослойные перцептроны, эта проблема была преодолена. Многослойные перцептроны с нелинейными функциями активации могут решать нелинейно сепарабельные задачи и обладают более высокой выразительностью и адаптивностью.
8. Aká je logická podstata Wienerovho filtra ?
    Какова логическая сущность фильтра Винера?
    Фильтр Винера - это статистический фильтр, который используется для восстановления идеального сигнала из зашумленного сигнала. Он основан на минимизации среднеквадратичной ошибки между ожидаемым и фактическим сигналом. Фильтр Винера применяется в области обработки сигналов для улучшения качества и восстановления исходного сигнала.
9. Je metóda najstrmšieho zostupu cestou k hľadaniu riešení Wienerovho systému rovníc ?
    Является ли метод наискорейшего спуска путем поиска решений системы уравнений Винера?
    Нет, метод наискорейшего спуска не является прямым путем поиска решений системы уравнений Винера. Метод наискорейшего спуска - это итерационный метод оптимизации, который используется для нахождения минимума или максимума функции путем последовательного изменения параметров в направлении, противоположном градиенту функции. Он широко применяется для обучения нейронных сетей, включая обратное распространение ошибки.

    Система уравнений Винера относится к оптимальной фильтрации и статистическому восстановлению сигнала. Она использует статистические модели и методы для нахождения оптимальных весов и параметров фильтра.
10. Aký je rozdiel medzi metódou najstrmšieho zostupu a metódy najmenšej strednej kvadratickej chyby?
    В чем разница между методом наискорейшего спуска и методом наименьших среднеквадратических ошибок?
    Метод наискорейшего спуска и метод наименьших среднеквадратических ошибок являются двумя разными методами оптимизации.

    Метод наискорейшего спуска является итерационным методом оптимизации, который используется для нахождения минимума или максимума функции путем последовательного изменения параметров в направлении, противоположном градиенту функции. Он обновляет параметры сети на каждой итерации с использованием скорости обучения и градиента функции.

    Метод наименьших среднеквадратических ошибок (МНСК) является специфическим случаем метода наискорейшего спуска. Он используется для нахождения оптимальных параметров или весов модели путем минимизации среднеквадратической ошибки между прогнозируемыми и фактическими значениями. МНСК является часто используемым методом в задачах регрессии и обучении с учителем.
11. Aký je rozdiel medzi Adaline a perceptrónom?
    В чем разница между Adaline и перцептроном?
    Adaline (Адаптивный линейный элемент) и перцептрон - это две модели нейронных сетей, которые имеют некоторые сходства, но также и отличия.

    Adaline является модификацией перцептрона, которая использует линейную функцию активации вместо пороговой функции, используемой в перцептроне. Adaline также использует алгоритм градиентного спуска для обучения и корректировки весов. Однако, в отличие от перцептрона, Adaline стремится минимизировать среднеквадратическую ошибку весов вместо обновления их по мере появления ошибки классификации.

    Таким образом, Adaline является более гибкой моделью, которая может обучаться на непрерывных значениях и решать задачи регрессии, в то время как перцептрон ориентирован на задачи классификации.

- ## 2. tutoriál
1. Aká je logika a cieľ Delta pravidla ?
2. Aký je rozdiel medzi Delta pravidlom a zovšeobecneným Delta pravidlom - ZDP (metódou spätného šírenia chyby) ?
3. Je odvodenie zmeny SV rovnaké vo všetkých častiach NN?
4. Odvoďte ZDP pre vybranú aktivačnú funkciu !
5. Vysvetlite prístupy k urýchleniu konvergencie BP-učenie; Prečo chceme vlastne urýchľovať učenie NN? čo sú heuristické pravidlá?
6. Aký je rozdiel medzi funkciami J a J v odvádzaní Delta-bar-delta pravidla ?
7. Ako je možné použiť fuzzy logiku na urýchlenie BP učenia?
8. Kde sa dajú využiť time-delay NN?
9. Aké sú vaše komentáre na nasledovné problémy pri návrhu a činnosti NN?
    - Akou topológiou začať?
    - Ako hladať optimálnu topológiu ? Koľko je potrebných skrytých vrstiev NN?
    - čo znamená univerzálna aproximačná teória?
    - Aká by bola ideálna forma inicializácie?
    - Má veľkosť trénovacej množiny význam pri kontrolovanom učení?

- ## 3. tutoriál
1. Aká je logika nekontrolovaného učenia? Ake typy úloh sa dajú riešiť na dopredných sieťach s takýmto typom učenia?
2. čím sa vyznačuje topológia MAXNET?
3. Aký je princíp učenia víťaz berie všetko?
4. Prečo je nutné normalizovať vstupné vektory pre konkurenčné učenie na dopredných NN? čo vlastne vypočítame pri skalárnom súčine normalizovaných vektorov?
5. čo je výsledkom celého procesu konkurenčného učenia na dopredných sieťach?
6. čím sa Kohonenove siete líšia od základného konkurenčného učenia?
7. Vysvetlite graf váh Kohonenovej NN!
8. Aká je logika zhustenia dát pomocou nekontrolovaného BP učenia na doprednej sieti ?
9. Aký význam má metóda hlavných komponentov a k čomu slúži?
10. Odvoďte Ojove pravidlo!
11. Aký je rozdiel medzi nekontrolovaným BP učením a učením Counterpropagation?

- ## 5. tutoriál
1. Vysvetlite základný princíp schémy rozpoznávania
2. Vysvetlite základný princíp schémy hĺbokého učenia a porovnajte rozdiel medzi hlbokými a plytkými neurónovými sieťami
3. Vysvetlite pojmy hyperparametre a parametre pri HU
4. Vysvetlite čo je to konvolúcia dvoch matematických funkcií a aký je rozdiel medzi konvolúciou a kros-koreláciou
5. čo je to chybový priestor a vysvetlite ho na CNNSIMPLE neurónovej sieti. Aký je rozdiel medzi Loss funkciou a optimizerom pri učení neurónových sietí.
6. Aké grafické karty poznáte od jakých výrobcov ?
7. Čo sú to AI počítače a čo sú Edge-počítače pre AI a aké majú výkony - ako ich meráme?
8. Aké sú architektúry počítačov resp. procesorov TURING, Da VINCI. Aký je rozdiel medzi CPU, GPU, TPU a NPU procesormi.
9. ktoré firmy vyrábajú počítače pre AI
10. ktorá téma z oblasti neuronových sietí Vás zaujala (ak vôbec) ? Máte pocit že sa oplatí vidieť hlbšie do neurónových sietí ? Aká je Vaša ambícia chcete byt “Marek” alebo “Gabriela” ?
